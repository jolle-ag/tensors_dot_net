{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial 2: Tensor Decompositions\n",
    "\n",
    "### As found in [here.](https://www.tensors.net/p-tutorial-2)\n",
    "\n",
    "This tutorial covers the basics of decomposing tensors into products of other tensors, including:\n",
    "\n",
    "* Diagonal, unitary and isometric tensors.\n",
    "* Use of singular value decomposition 'svd' to decompose tensors.\n",
    "* Use of spectral decomposition 'eig' to decompose tensors.\n",
    "* Use of QR decomposition 'qr'.\n",
    "* The Frobenius norm and optimal restricted rank tensor truncations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from ncon import ncon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonal, unitary and isometric tensors\n",
    "\n",
    "We begin by considering some special types of tensors and their diagrammatic representation:\n",
    "\n",
    "<img src=\"img/tut_2_fig_1.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "which from left to right are the identity matrix, a diagonal matrix D and a diagonal tensor.\n",
    "\n",
    "Unitary matrices annihilate to the identity with its conjugate $U^\\dagger$ and we often use arrows to indicate unitarity. In the case of a tensor, it is unitary if there exists a bipartition of the indices (denoted by a dotted line) under which the tensor could be reshaped into a unitary matrix:\n",
    "\n",
    "<img src=\"img/tut_2_fig_2_unitaries.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "Isometric matrices will have different dimensions in the indices, $d_1 > d_2$ w/o l.o.g. . When contracted on the larger dimensional index with its conjugate the identity is produced, $W^\\dagger W = 1$. However, contraction on the other way, $W W^\\dagger = P$ produces a projector P:\n",
    "\n",
    "<img src=\"img/tut_2_fig_3_isometric_matrices.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "Something similar to the diagrammatic notation for unitaries happens for isometric tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor decompositions\n",
    "\n",
    "In this section we discuss how several common matrix decompositions, including the SVD, the spectral decomposition and the QR decomposition are generalized to the case of tensors.\n",
    "\n",
    "#### Singular Value Decomposition (SVD)\n",
    "\n",
    "Given a $d_1 \\times d_2$ matrix A (where $d_1 > d_2$ has been assumed), we want to write it as a product of matrices, $A = U S V^\\dagger$, where $U$ is a $d_1 \\times d_2$ isometric matrix, $V$ is a $d_2 \\times d_2$ unitary matrix and $S$ is a $d_2 \\times d_2$ diagonal matrix with positive, real elements ordered in descending magnitude (called the singular values). The cost of performing the SVD is $O(d_1 d_2^2)$.\n",
    "\n",
    "In the case of a tensor $A$ of $\\text{rank} \\geq 3$, the whole thing proceeds equally as before once we have reshaped $A$ appropriately. The only difference, though, is that $U$ will be an isometric tensor.\n",
    "\n",
    "<img src=\"img/tut_2_svd.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3505547907798496e-15\n"
     ]
    }
   ],
   "source": [
    "# Example code: SVD of a matrix\n",
    "d1 = 10; d2 = 6\n",
    "\n",
    "A = np.random.rand(d1,d2)\n",
    "\n",
    "[U,S,Vh] = LA.svd(A,full_matrices=False) # If true we would have extra dimensions with zeros\n",
    "\n",
    "# To check result we contract U,S,Vh and we should get A\n",
    "Af = U @ np.diag(S) @ Vh\n",
    "\n",
    "print(LA.norm(Af-A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2396592612591374e-14\n"
     ]
    }
   ],
   "source": [
    "# Example code: SVD of a tensor\n",
    "d = 10\n",
    "\n",
    "A = np.random.rand(d,d,d)\n",
    "\n",
    "Am = A.reshape(d**2, d)\n",
    "\n",
    "# Now it proceeds as SVD of a matrix\n",
    "Um,Sm,Vh = LA.svd(Am,full_matrices=False)\n",
    "\n",
    "U = Um.reshape(d,d,d); S = np.diag(Sm)\n",
    "\n",
    "# check result\n",
    "Af = ncon([U,S,Vh],[[-1,-2,1],[1,2],[2,-3]])\n",
    "\n",
    "print(LA.norm(Af-A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aside:\n",
    "\n",
    "The SVD is also a useful way of generating random unitary and isometric tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how SVD can generate random unitaries and isometries\n",
    "d1 = 10; d2 = 6;\n",
    "\n",
    "# d1-by-d1 random unitary matrix U\n",
    "U,_,_ = LA.svd(np.random.rand(d1,d1))\n",
    "\n",
    "# d1-by-d2 random isometric matrix W\n",
    "A = np.random.rand(d1,d2);\n",
    "W,_,_ = LA.svd(A, full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral decomposition:\n",
    "\n",
    "Also known as \"diagonalizing a Hamiltonian\", where we decompose a $d \\times d$ Hermitian matrix $H$ into $H = U D U^\\dagger$, where $U$ is unitary and $D$ is the diagonal matrix of eigenvalues of $H$. Its cost scales as $O(d^3)$.\n",
    "\n",
    "In the case of a tensor, the same thing applies after using the appropriate 'reshape' commands. The differences though, are that the number of eigenvalues is now the product of the indices on each side of $H$, and the tensor $U$ is reshaped into a order $> 2$ isometry.\n",
    "\n",
    "<img src=\"img/tut_2_spectral.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.976362627855249e-15\n"
     ]
    }
   ],
   "source": [
    "# Example code of the spectral decomposition of a Hermitian matrix\n",
    "d = 10\n",
    "A = np.random.rand(d,d)\n",
    "H = 0.5*(A + A.T) # This is a way of making it Hermitian\n",
    "\n",
    "D, U = LA.eigh(H)\n",
    "\n",
    "# Check result\n",
    "Hf = U @ np.diag(D) @ U.T\n",
    "\n",
    "print(LA.norm(Hf-H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1502272644110215e-15\n"
     ]
    }
   ],
   "source": [
    "# Example code of the spectral decomposition of a Hermitian tensor\n",
    "d = 2\n",
    "A = np.random.rand(d,d,d,d)\n",
    "H = 0.5*(A + A.transpose(2,3,0,1)) # Now we transpose according to diagrammatic rep.\n",
    "\n",
    "D, U = LA.eigh(H.reshape(d**2,d**2))\n",
    "U = U.reshape(d,d,d**2)\n",
    "\n",
    "# Check result\n",
    "Hf = ncon([U,np.diag(D),U], [[-1,-2,1],[1,2],[-3,-4,2]])\n",
    "\n",
    "print(LA.norm(Hf-H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aside:\n",
    "\n",
    "For any matrix $A$, the spectral decompositions of $A A^\\dagger$ and $A^\\dagger A$ are related to the SVD of A as depicted in the following fig:\n",
    "\n",
    "<img src=\"img/tut_2_svd_vs_spectral.png\" alt=\"drawing\" width=\"550\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QR decomposition\n",
    "\n",
    "This is the final decomposition that we consider, and is useful to orthogonalize a TN, as will be discussed later in tutorial 3.\n",
    "\n",
    "Given a $d_1 \\times d_2$ matrix $A$, we want to write it as $A = QR$, where $Q$ is a $d_1 \\times d_2$ isometric matrix and $R$ is a $d_2 \\times d_2$ upper-triangular matrix. The cost scales as $O(d_1 d_2^2)$, which is the same as the SVD, though QR tends to be faster in practice by a constant factor.\n",
    "\n",
    "Again, through appropriate reshaping, this method can be applied to tensors as well.\n",
    "\n",
    "<img src=\"img/tut_2_QR.png\" alt=\"drawing\" width=\"550\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.836601059614785e-16\n"
     ]
    }
   ],
   "source": [
    "# Example code of QR decomposition of a matrix\n",
    "d1 = 10; d2 = 6\n",
    "A = np.random.rand(d1,d2)\n",
    "\n",
    "Q,R = LA.qr(A)\n",
    "\n",
    "# Check result\n",
    "Af = Q @ R\n",
    "\n",
    "print(LA.norm(Af-A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2209713900338e-15\n"
     ]
    }
   ],
   "source": [
    "# Example code of QR decomposition of a tensor\n",
    "d = 10\n",
    "A = np.random.rand(d,d,d)\n",
    "\n",
    "Qm,R = LA.qr(A.reshape(d**2,d))\n",
    "Q = Qm.reshape(d,d,d)\n",
    "\n",
    "# Check result\n",
    "Af = ncon([Q,R], [[-1,-2,1],[1,-3]])\n",
    "\n",
    "print(LA.norm(Af-A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frobenius norm for tensors\n",
    "\n",
    "Given a matrix $A$, the norm $||A||$ is defined as the square-root of the sum of the magnitude of each element squared,\n",
    "$$||A|| = \\sqrt{\\sum_{ij} |A_{ij}|^2} = \\sqrt{\\text{tr} (A^\\dagger A)}.$$\n",
    "The extension to tensors with order $> 2$ is very straight-forward; either extend the summation to include all indices or replace the trace with a tensor trace Ttr. In Python, the Frobenius norm is already LA.norm(A).\n",
    "\n",
    "A useful property of the Frobenius norm is that $\\text{Ttr}(A^\\dagger A)$ is the square root of the sum of the singular values squared:\n",
    "\n",
    "$$\\text{Ttr}(A^\\dagger A) = \\sum_k s_k^2.$$\n",
    "\n",
    "The proof is obvious and very nice to see visually using tensor diagrams:\n",
    "\n",
    "<img src=\"img/tut_2_frobenius_svd_proof.png\" alt=\"drawing\" width=\"550\"/>\n",
    "\n",
    "The usefulness of the Frobenius norm comes when approximating some tensor $A$ with another tensor $B$ of equal size. It's useful to define the error of the approximation $\\varepsilon$ as\n",
    "\n",
    "$$\\varepsilon = \\frac{||A - B||}{||A||}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted rank tensor approximations\n",
    "\n",
    "We're given some tensor $A$ and some bipartition of its indices. If $A$ can be written as $A = B \\cdot C$, we define the decomposition rank $r$ as the dimension of the index contracted between $B$ and $C$. Although this will not be proved here, it can be shown that the decomposition rank $r$ of tensor $A$ across a partition precisely equals the number of non-zero singular values in the SVD across the partition.\n",
    "\n",
    "A useful application of the SVD thus is that it allows one to find the optimal restricted rank approximation to a tensor. Given a tensor $A$ that has decomposition rank $r$ with respect to some specified partition of its indices, let's assume that we wish to find an equivalent sized tensor $B$ of reduced rank, $\\chi < r$, that best approximates $A$.\n",
    "\n",
    "The factorization that minimizes the truncation error $\\varepsilon$ can be obtained directly from the SVD of $A$ by simply 'trimming' the smallest singular values and truncating the $U$ and $V$ matrices accordingly. This is demonstrated below by approximating order-5 tensor $A$ with an order-5 tensor $B$ that has rank $\\chi = 8$ across the partition indicated, using the truncated SVD:\n",
    "\n",
    "<img src=\"img/D15.png\" alt=\"drawing\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "d = 10\n",
    "A = np.random.rand(d,d,d,d,d)\n",
    "\n",
    "# SVD\n",
    "Um, S, Vhm = LA.svd(A.reshape(d**3,d**2), full_matrices=False)\n",
    "U = Um.reshape(d,d,d,d**2)\n",
    "Vh = Vhm.reshape(d**2,d,d)\n",
    "\n",
    "# Truncation\n",
    "def trunc(chi):\n",
    "    Vht = Vh[:chi,:,:]\n",
    "    St = np.diag(S[:chi])\n",
    "    Ut = U[:,:,:,:chi]\n",
    "\n",
    "    B = ncon([Ut,St,Vht],[[-1,-2,-3,1],[1,2],[2,-4,-5]])\n",
    "    \n",
    "    return B\n",
    "\n",
    "# Comparison\n",
    "epsL = []\n",
    "for chi in range(1,d**2):\n",
    "    B = trunc(chi)\n",
    "    epsAB = LA.norm(A-B)/LA.norm(A)\n",
    "    epsL.append(epsAB)\n",
    "#    print('chi:'+str(chi)+', eps:'+str(round(epsAB,4))+', t:'+str(round(tf-t0,4))+'s')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(range(1,d**2), np.log(epsL)/np.log(10))\n",
    "plt.xlabel('chi')\n",
    "plt.ylabel('Log10(eps)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful concept is the effective rank to accuracy $\\Delta$ of a tensor, denoted as $r(\\Delta)$ and defined as the number of singular values greater than or equal to $\\Delta$ across the decomposition. In many cases (particularly if the spectrum of singular values is sharply decaying) then the error $\\varepsilon$ in truncating a tensor to rank $r(\\Delta)$ will be $\\varepsilon \\approx \\Delta$, since $\\varepsilon = \\sqrt{\\sum_{k > \\chi} s_k^2}$ will be dominated by the largest singular value that is truncated. Thus the value $\\Delta$ often serves as a useful proxy for the true truncation error $\\varepsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta:0.01, r(delta):450, eps:0.0404\n"
     ]
    }
   ],
   "source": [
    "# Example: effective rank\n",
    "d = 500\n",
    "\n",
    "# We will generate a Toeplitz matrix\n",
    "A = np.diag(np.ones(d-1),-1) + np.diag(np.ones(d-1),1)\n",
    "A /= LA.norm(A)\n",
    "\n",
    "# Compute effective rank to accuracy 'deltaval'\n",
    "deltaval = 1e-2\n",
    "Um, Sm, Vhm = LA.svd(A)\n",
    "\n",
    "r_delta = sum(Sm > deltaval) # This gives the number of elements in Sm larger than deltaval\n",
    "\n",
    "eps_err = np.sqrt(sum(Sm[r_delta:]**2)) # Associated error to r_delta\n",
    "\n",
    "print('delta:'+str(deltaval)+', r(delta):'+str(r_delta)+', eps:'+str(round(eps_err,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook: Tensor Decompositions\n",
    "\n",
    "Optimal restricted rank tensor approximations play a central role in TN theory and are also essential ingredients to most TN algorithms. In fact, most common TN algorithms are simply composed of some combination of contraction steps (see Tutorial 1), together with some combination of tensor decompositions. Thus we have already learned the foundational tools of TN methods!\n",
    "\n",
    "Subsequent tutorials will discuss how these tools can be applied and composed into algorithms for certain tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 2:\n",
    "\n",
    "Tensor $A$ is an order-4 tensor that we define element-wise as:\n",
    "\n",
    "<img src=\"img/D21.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "**(a)** Assume that indices i,j are of dimension $d_1$ and indices k, l are of dimension $d_2$ ($d_2 < d_1$ as usual). How does the cost of taking the SVD across the indicated partition scale with $d_1$ and $d_2$?\n",
    "\n",
    "**(b)** Generate the tensor $A$ for $d_1=10$ and $d_2 = 8$. What is the norm $||A||$? After computing the norm construct the normalized tensor $A \\to \\frac{A}{||A||}$.\n",
    "\n",
    "**(c)** Take the SVD of $A$ across the indicated partition. Check that the square root of the sum of the singular values squared is equal to 1. Why is this the case?\n",
    "\n",
    "**(d)** What is the effective rank $r(\\Delta)$ of $A$ at $\\Delta = 1\\text{e-4}$?\n",
    "\n",
    "**(e)** Compute the truncation error $\\varepsilon$ of the restricted rank approximation $r(\\Delta = 1\\text{e-4})$ indirectly using the singular values $\\left(\\varepsilon = \\sqrt{\\sum_{k > \\chi} s_k^2} \\right)$.\n",
    "\n",
    "**(f)** Construct the optimal restricted rank approximation to A via the truncated SVD. Compute the truncation error $\\varepsilon$ of this approximation and check that your answer is consistent with part (e).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Solutions:\n",
    "\n",
    "**(a)** For a matrix with dimensions $d_1$ and $d_2$ ($d_2 < d_1$) the cost of SVD scales as $O(d_1 d_2^2)$. In our case, we can reshape $A$ into a matrix with dimensions $d_1^2$ and $d_2^2$. Therefore, the cost of the SVD of A will be $O(d_1^2 d_2^4)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554.2562584220408\n"
     ]
    }
   ],
   "source": [
    "# Generate A with d1=10 and d2=8\n",
    "d1 = 10; d2 = 8\n",
    "\n",
    "A = np.zeros((d1,d1,d2,d2))\n",
    "\n",
    "for i in range(d1):\n",
    "    for j in range(d1):\n",
    "        for k in range(d2):\n",
    "            for l in range(d2):\n",
    "                A[i,j,k,l] = np.sqrt(i + 2*j + 3*k + 4*l + 10)\n",
    "\n",
    "# Norm of A\n",
    "print(LA.norm(A))\n",
    "\n",
    "# Normalize A\n",
    "A /= LA.norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# Take SVD\n",
    "Um, S, Vhm = LA.svd(A.reshape(d1**2,d2**2), full_matrices=False)\n",
    "\n",
    "U = Um.reshape(d1,d1,d2**2)\n",
    "Vh = Vhm.reshape(d2**2,d2,d2)\n",
    "\n",
    "# Check that singular values 'sum' to 1\n",
    "s_sum = np.sqrt(sum(S**2))\n",
    "\n",
    "print(s_sum)\n",
    "\n",
    "# They sum to 1 because ||A||=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** and **(e)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta:0.0001, r(delta):3, eps:1.048e-05\n"
     ]
    }
   ],
   "source": [
    "# Effective rank r_delta at deltaval = 1e-4\n",
    "deltaval = 1e-4\n",
    "\n",
    "r_delta = sum(S > deltaval) # This gives the number of elements in S larger than deltaval\n",
    "\n",
    "eps_err = np.sqrt(sum(S[r_delta:]**2)) # Associated error to r_delta\n",
    "\n",
    "print('delta:'+str(deltaval)+', r(delta):'+str(r_delta)+', eps:'+str(round(eps_err,8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** Optimal restricted rank approximation to $A$ means taking $\\chi = r(\\Delta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.048e-05\n"
     ]
    }
   ],
   "source": [
    "# Truncation\n",
    "def trunc(chi):\n",
    "    Vht = Vh[:chi,:,:]\n",
    "    St = np.diag(S[:chi])\n",
    "    Ut = U[:,:,:chi]\n",
    "\n",
    "    B = ncon([Ut,St,Vht],[[-1,-2,1],[1,2],[2,-4,-5]])\n",
    "    \n",
    "    return B\n",
    "\n",
    "# Comparison\n",
    "chi = r_delta\n",
    "B = trunc(chi)\n",
    "epsAB = LA.norm(A-B)\n",
    "print(round(epsAB,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that errors in **(e)** and **(f)** are identical up to numerical accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
